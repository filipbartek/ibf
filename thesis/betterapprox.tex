\chapter{\approxtitle{Interval decomposition}}
\label{chap:betterapprox}

The $2k$-approximation
suffix-prefix decomposition algorithm
introduced in \autoref{chap:2kapprox}
can be naturally improved
by spanning each of the $k$ intervals
of the given $k$-interval function
optimally using the minimization algorithm
introduced in \autoref{chap:1interval}
(originally in \citet{Schieber2005154}).
We will call this improved algorithm
\quot{interval decomposition algorithm}.

Since the interval decomposition algorithm
clearly performs at least as well
as the suffix-prefix decomposition algorithm,
it is $2k$-approximation as well.
\citeauthor{Dubovsky2012} has managed
to prove that on $2$-interval functions,
the interval decomposition algorithm
has an approximation ratio $2$
\citep[p.~39]{Dubovsky2012}, % Theorem 4.2
while the suffix-prefix decomposition algorithm
has a tight approximation ratio $4$
on $2$-interval functions
(see \autoref{theorem:2kapproxtight}).
This might lead us to expect
that the interval decomposition algorithm
performs significantly better in general.
However,
we will show in this chapter that its approximation ratio
converges to $2k$ for large $k$
(and namely that it is strictly larger than $k$
for $k > 2$).
\todo{Do we really prove this for all $k$s? Try to!}

\section{Algorithm description}

\todo[inline]{Label or name the algorithm properly and then refer to it consistently.}

\begin{description}
\item[Input] Numbers $a_1, b_1, \ldots, a_k, b_k$
encoded as binary vectors of length $n$
that satisfy the inequalities
$\rep{0}{n} \leq a_1$,
$a_1 \leq b_1$,
$b_1 < a_2 - 1$,
\ldots,
$a_i \leq b_i$,
$b_i < a_{i+1} - 1$
(for $i \in \curly{1, \ldots, k-1}$),
\ldots,
$b_{k-1} < a_k - 1$,
$a_k \leq b_k$,
$b_k \leq \rep{1}{n}$.

Such numbers are endpoints of intervals
of a proper $k$-interval Boolean function.

\item[Output] A set of ternary vectors.
\todomaybe{Add \quot{that spans
$\fnkab$}.}

\item[Procedure]
The algorithm spans each of the $k$ intervals
$\interval{a_i}{b_i}$ separately.
For every $i$,
let $\mathcal{T}_i$ be the spanning set of the interval
$\interval{a_i}{b_i}$ returned by the $1$-interval
optimization algorithm
introduced in \autoref{chap:1interval}.
The algorithm returns
$\mathcal{T} = \bigcup_{i=1}^k{\mathcal{T}_i}$.
\end{description}

Note that the spanning set constructed
by the interval decomposition algorithm
need not be disjoint
(unlike the spanning set constructed
by the suffix-prefix decomposition algorithm).
If we used \citeauthor{Schieber2005154}
disjoint $1$-interval spanning set minimization algorithm
\citep{Schieber2005154},
we would obtain a disjoint spanning set.
We will not analyze the approximation ratio in this case.
% We would need to find a good disjoint representation of hard functions.

\section{Approximation ratio}

Let $F$ be a class of Boolean functions.
We shall denote the worst case approximation ratio
of the interval decomposition algorithm
on functions from class $F$ with $\approxid{F}$:
$$
\approxid{F}
= \sup_{f \in F}{\frac{id(f)}{dnf(f)}}
$$
\todo{Is this definition of approximation ratio correct?
I'm afraid it may be inconsistent with some parts of the text.}
where $id(f)$ is the size of the spanning set of $f$
returned by the interval decomposition algorithm.

We will analyse the approximation ratio
of the interval decomposition algorithm
on $k$-interval Boolean functions,
that is $\approxidintk$,
where $\intervalfns{k}$ is the class
of $k$-interval Boolean functions.
We will parametrize the approximation ratio
with the number of intervals $k$.

\subsection{Upper bound of $2k$}

Since the interval decomposition algorithm
spans each of the $k$ intervals separately and optimally,
while the suffix-prefix decomposition algorithm
spans each of them separately and possibly non-optimally,
we get an upper bound $2k$
on $\approxidintk$ by \cref{theorem:2kapproxratio}:
$$
\approxidintk \leq \approxspdintk = 2k
$$
However,
the ratio $2k$ need not be tight
for the interval decomposition algorithm.
We will continue to analyze the lower bounds
on the approximation ratio.

\subsection{Known lower bounds for $k \in \curly{1, 2}$}

\citeauthor{Dubovsky2012} has shown
that the approximation ratio is strictly smaller than $2k$
for $k = 2$,
as the algorithm is $2$-approximation
in this case \citep[p.~39]{Dubovsky2012}. % Theorem 4.2
Similarly,
it is obvious that the algorithm
gives an optimal result in case $k = 1$
(which corresponds to the approximation ratio $1$).
\begin{align*}
\approxidint{1} &= 1 \\
\approxidint{2} &= 2
\end{align*}

In the following sections,
we will construct a class of Boolean functions
on some of which
the interval decomposition algorithm
performs strictly worse than $k$-approximately
for $k = 3$.
\todo{Reformulate the sentence.}
\todomaybe{Try to prove this for all $k > 2$.}
We will generalize this to show
that the approximation ratio converges to $2k$
for large $k$.

\subsection{Approximation-hard functions}
\todo[inline]{Don't call the functions \quot{hard}.}

In this section we shall describe a class of functions
on which the interval decomposition algorithm
performs particularly badly.
For every $l \geq 1$ and $n \geq l+2$,
we will construct
a proper $(2^{l-1} + 1)$-interval $n$-ary function $f_l^n$.

Let $l \geq 1$
denote a parameter that determines the number of intervals of the target function $f_l^n$.
Its exact meaning will be explained in the description of the construction of $f_l^n$.
Let $n \geq l+2$
denote the arity of the target function $f_l^n$
(and thus the length of its points,
especially the interval endpoints).
Let $k$ denote the number of intervals of $f_l^n$.
After we define the intervals,
we will show that $k = 2^{l-1} + 1$.

All the interval endpoints have a prefix of length $l$
that specifies the \quot{position} of the interval
and a suffix of length $n - l$
that specifies the interval's \quot{shape}.
We will denote the $l$-bit \quot{position} prefix
of an $n$-bit binary vector $x$ with $p_x$
($p_x = \bits{x}{1}{l}$)
and the $(n-l)$-bit \quot{shape} suffix with $s_x$
($s_x = \bits{x}{l+1}{n}$).
Note that $x = p_x s_x$.

The \quot{shape} is identical for all the intervals
of a given $f_l^n$
-- for every $i \in \curly{1, \ldots, k}$:

\begin{itemize}
\item $s_{a_i} = \rep{0}{n-l-1} 1$
\item $s_{b_i} = \rep{1}{n-l-1} 0$
\end{itemize}

Note that for $n \geq l + 3$,
this \quot{shape} corresponds to an extreme
non-trivial endpoint combination in the $1$-interval
optimization algorithm
(namely case \quot{$b' \geq a' - 1$}
in \autoref{sec:1interval0011}),
which happens to be the case where the improvement
of the optimization algorithm
over the suffix-prefix approximation algorithm
is the largest.

We construct the \quot{position} prefixes of the endpoints
so that they
satisfy the following requirements:

\begin{enumerate}
\item \label{item:hardint1}
$p_{a_1} = p_{b_1} = \rep{0}{l}$
\item \label{item:hardintk}
$p_{a_k} = p_{b_k} = \rep{1}{l}$
\item \label{item:hardlength}
$p_{b_i} = p_{a_i} + 1$
for $i \in \curly{2, \ldots, k-1}$
\item \label{item:hardspacing}
$p_{a_{i+1}} = p_{b_i} + 1$
for $i \in \curly{1, \ldots, k-1}$
\end{enumerate}

Using these requirements,
we can inductively construct a sequence of $l$-bit numbers
$p_{a_1}, p_{b_1}, p_{a_2}, p_{b_2}, \ldots,
p_{a_k}, p_{b_k}$.
We start with
$p_{a_1} = p_{b_1} = \rep{0}{l}$
by requirement \ref{item:hardint1}.
We follow by
constructing $p_{a_{i+1}}$ from $p_{b_i}$
for $i \in \curly{1, 2, \ldots}$
using requirement \ref{item:hardspacing} and
constructing $p_{b_i}$ from $p_{a_i}$
for $i \in \curly{2, 3, \ldots}$
using requirement \ref{item:hardlength}.
Note that the $p_{a_i}$s constructed this way
for $i \in \curly{2, 3, \ldots}$
systematically
\todomaybe{Use a better term.}
exhaust odd numbers,
since $p_{a_2} = \rep{0}{l-1} 1$
(recall that we require $l \geq 1$)
and $p_{a_{i+1}} = p_{a_i} + 2$.
We stop the induction
as soon as we get to an index $k$ such that
$p_{a_k} = \rep{1}{l}$.
Since $p_{a_i}$s systematically exhaust odd numbers,
there must be such $k$.
\todomaybe{Add \quot{Moreover, $k = 2^{l-1} + 1$}, possibly with some simple analysis.}
We terminate by constructing $p_{b_k} = \rep{1}{l}$
by requirement \ref{item:hardintk}.

Note that the sequence is defined unambiguously
for a given $l$.

The construction of $p_{a_i}$ and $p_{b_i}$
together with the definition
of $s_{a_i}$ and $s_{b_i}$ define a set of points
$a_i = p_{a_i} s_{a_i}$ and $b_i = p_{b_i} s_{b_i}$
for $i \in \curly{1, \ldots, k}$.
To see that points defined this way
satisfy the requirements on endpoints
of a proper $k$-interval function
(see \autoref{def:properkibf}),
note that:

\begin{itemize}
\item $a_1 \leq b_1$ by requirement \ref{item:hardint1}
and the fact that $s_{a_1} \leq s_{b_1}$
\item $a_i \leq b_i$
for $i \in \curly{2, \ldots, k-1}$
by requirement \ref{item:hardlength}
\item $b_i < a_{i+1} - 1$
for $i \in \curly{1, \ldots, k-1}$
by requirement \ref{item:hardspacing}
and the fact that $s_{a_i} > \rep{0}{l}$
(or $s_{b_i} < \rep{1}{l}$)
\item $a_k \leq b_k$ by requirement \ref{item:hardintk}
and the fact that $s_{a_k} \leq s_{b_k}$
\end{itemize}

To see that the number of intervals $k$ is $2^{l-1} + 1$,
we will count the \quot{subtrees}
intersected by the intervals.

\begin{definition}[Subtree]
Let $p$ be a binary vector of length $l$
and $n \geq l$.
Then \definiendum{level $l$ $p$-subtree} is the interval
$\interval{p \; \rep{0}{n-l}}{p \; \rep{1}{n-l}}$.
\end{definition}

Clearly there are $2^l$ level $l$ subtrees
that partition the full interval
$\interval{\rep{0}{n}}{\rep{1}{n}}$.

The requirements
\ref{item:hardint1} and \ref{item:hardintk}
force each of the intervals
$\interval{a_1}{b_1}$ and $\interval{a_k}{b_k}$
to intersect exactly 1 level $l$ subtree
(the $\rep{0}{l}$-subtree
and the $\rep{1}{l}$-subtree respectively).

The requirement \ref{item:hardlength}
forces each of the intervals
$\interval{a_i}{b_i}$ for $i \in \curly{2, \ldots, k-1}$
to intersect exactly 2 level $l$ subtrees
(the $p_{a_i}$-subtree and the $(p_{a_i}+1)$-subtree).

The requirement \ref{item:hardspacing}
forces each adjacent pair of intervals
to intersect adjacent level $l$ subtrees
and not to intersect a common subtree.
Since by requirements
\ref{item:hardint1} and \ref{item:hardintk}
the $\rep{0}{l}$-subtree
and the $\rep{1}{l}$-subtree
are intersected by some intervals,
each of the level $l$ subtrees is intersected
by some interval.

Since there are $2^l$ level $l$ subtrees,
each of them is intersected by exactly one interval,
the first and the $k$-th interval intersect
one subtree each
and the remaining intervals intersect 2 subtrees each,
there are $2 + \frac{2^l - 2}{2} = 2^{l-1} + 1 = k$
intervals in total.

Equivalently,
if we are looking for a \quot{hard} function
with at least $k$ proper intervals,
we can construct it using the parameter
$l = \ceil{\log_2{(k-1)} + 1}$.

\subsection{Interval decomposition spanning set size}

Let $f_l^n =
f^n_{\interval{a_1}{b_1}, \ldots, \interval{a_k}{b_k}}$
be a $k$-interval function
constructed using the definition
shown in the previous section.
\todo{Refer by number.}
In this section we will show the size of the spanning set
returned by the interval decomposition algorithm
when run on this function.
We will denote its size with $id(f_l^n)$.

The interval decomposition algorithm spans
each of the intervals separately
using the optimization algorithm
from \autoref{chap:1interval},
so $id(f_l^n) = \sum_{i=1}^k{\size{\mathcal{T}_i}}$,
where $\mathcal{T}_i$ is the spanning set
of the interval $\interval{a_i}{b_i}$
returned by the optimization algorithm
for $1$-interval functions.

For every $i$,
we will analyse how the $1$-interval algorithm solves
the instance $\interval{a_i}{b_i}$.
We will divide the analysis between the intervals
such that $p_{b_i} = p_{a_i}$
and the ones such that $p_{b_i} = p_{a_i} + 1$.

\subsubsection{$i \in \curly{1, k}$}

In case $i \in \curly{1, k}$,
the endpoints have common prefixes of length $l$
($p_{b_i} = p_{a_i}$).
Thus the instance $\interval{a_i}{b_i}$
is reduced to the instance
$\interval{s_{a_i}}{s_{b_i}}
= \interval{\rep{0}{n-l-1} 1}{\rep{1}{n-l-1} 0}$.

Recall that $n \geq l + 2$.

If $n = l + 2$,
the instance
$\interval{\rep{0}{n-l-1} 1}{\rep{1}{n-l-1} 0}
= \interval{01}{10}$
is spanned using the procedure
shown in \autoref{sec:1interval0110}.
This procedure spans the two trivial sub-intervals
$\interval{01}{01}$ and $\interval{10}{10}$
separately,
producing $2 = n-l$ ternary vectors.

If $n \geq l + 3$,
the instance
$\interval{\rep{0}{n-l-1} 1}{\rep{1}{n-l-1} 0}$
is spanned using the procedure
shown in \autoref{sec:1interval0011}.
This procedure reduces the instance
to the instance $\interval{01}{10}$,
which again contributes $2$ ternary vectors,
and adds $n-l-2$ extra ternary vectors
that span the sub-interval
$\interval{\rep{0}{n-l-2} 10}{\rep{1}{n-l-2} 01}$.
The spanning set of the interval in this case has the size
$2 + n - l - 2 = n - l$.

We conclude that in case $i \in \curly{1, k}$,
$\size{\mathcal{T}_i} = n-l$.

\subsubsection{$i \in \curly{2, \ldots, k-1}$}

In case $i \in \curly{2, \ldots, k-1}$,
recall that $p_{b_i} = p_{a_i} + 1$.
This means that $p_{a_i} = c 0 \rep{1}{m}$
and $p_{b_i} = c 1 \rep{0}{m}$
for some binary vector $c$
and number $m \in \curly{0, \ldots, l-1}$.

To see that $m \geq 1$,
recall that $p_{a_i}$ must be odd.

This means that $a_i$ and $b_i$
start with a common prefix $c$
followed by the bits $01$ in $a_i$
and $10$ in $b_i$.
In the $1$-interval optimization algorithm,
the common prefix $c$ is left out
and then the procedure
shown in \autoref{sec:1interval0110}
is applied to the remainder of the endpoints
(that is
$\interval{01 \rep{1}{m-1} s_{a_i}}
{10 \rep{0}{m-1} s_{b_i}}$).
This procedure spans the two sub-intervals
$\interval{\rep{1}{m} s_{a_i}}{\rep{1}{m+n-l}}$
and $\interval{\rep{0}{m+n-l}}{\rep{0}{m} s_{b_i}}$
separately using the suffix and prefix procedure
respectively.

Let's consider the sub-interval
$\interval{\rep{0}{m+n-l}}{\rep{0}{m} s_{b_i}}$;
the other one is symmetric.

Note that this sub-interval can be immediately reduced
to $\interval{\rep{0}{n-l}}{s_{b_i}}$
by removing the common prefix of the endpoints.

Recall that the prefix algorithm
produces one ternary vector
for each bit that is set to $1$
in $s_{b_i} + 1 = \rep{1}{n-l}$.
The returned spanning set of
$\interval{\rep{0}{n-l}}{s_{b_i}}$
thus has the size $n-l$.
Prepending the prefix $p_{b_i}$
we get a spanning set of
$\interval{p_{b_i} \rep{0}{n-l}}{p_{b_i} s_{b_i}}$.

We span the complementary sub-interval
$\interval{p_{a_i} s_{a_i}}{p_{a_i} \rep{1}{n-l}}$
in a symmetric manner,
getting another spanning set of size $n-l$.

Joining the sub-interval spanning sets together
we get the spanning set $\mathcal{T}_i$ of size $2(n-l)$.

\hfill

Putting the interval spanning sets together,
we get:
\begin{align*}
id(f_l^n) &= \sum_{i=1}^k{\size{\mathcal{T}_i}} \\
&= 2 (n-l) + \sum_{i=2}^{k-1}{2 (n-l)} \\
&= 2 (n-l) + (k-2) 2 (n-l) \\
%&= 2 (n-l) (1 + (k-2)) \\
&= 2 (n-l) (k-1) \\
&= 2 (n-l) ((2^{l-1} + 1) - 1) \\
%&= 2 (n-l) 2^{l-1} \\
&= 2^l (n-l)
\end{align*}

\subsection{Minimum spanning set size}

In this section we will show a spanning set
of $f^n_l$ of size $n+l-2$
and prove its optimality
($dnf(f^n_l) = n+l-2$).

\begin{lemma}
$dnf(f_l^n) \leq n+l-2$
\end{lemma}

\begin{proof}
We will show a spanning set $\mathcal{T}$
of $f_l^n$ of size $n+l-2$.

We will span the union of the intervals
$\interval{p \rep{0}{n-l-1} 1}{p \rep{1}{n-l-1} 0}$
for all $p \in \booldom^l$
using $n-l$ ternary vectors
and then we will add some extra vectors
to span the remaining true points.

First observe that all the false points of $f_l^n$
end with either $\rep{0}{n-l}$ or $\rep{1}{n-l}$.
This is clear from the definition
of the \quot{shape} endpoint suffixes
$s_{a_i} = \rep{0}{n-l-1} 1$
and $s_{b_i} = \rep{1}{n-l-1} 0$
and the fact that the intervals intersect every
level $l$ subtree.

This means we need to span all the points that end
with different $(n-l)$-bit suffixes.
We can do that with the set
$\mathcal{T}_{\mathit{out}}
= \curly{\rep{\phi}{l} s
| s \text{ is a cyclic shift of } 01 \rep{\phi}{n-l-2}}
= \curly{
\rep{\phi}{l} 01 \rep{\phi}{n-l-2},
\rep{\phi}{l} \phi 01 \rep{\phi}{n-l-3},
\ldots,
\rep{\phi}{l} 1 \rep{\phi}{n-l-2} 0
}
$.
To see that $\mathcal{T}_{\mathit{out}}$
spans all the points
that do not end with $\rep{0}{n-l}$ or $\rep{1}{n-l}$,
note that for every binary vector $x$
that contains both a $0$ and a $1$
there is a position $i$
such that $\bit{x}{i} = 0$
and $\bit{x}{(i+1) \bmod (n-l)} = 1$.
Thus we have spanned the union of the intervals
$\interval{p \rep{0}{n-l-1} 1}{p \rep{1}{n-l-1} 0}$
for all $p \in \booldom^l$
using $n-l$ ternary vectors.

Observe that
the true points
that end with $\rep{1}{n-l}$
are exactly all the points $p_{a_i} \rep{1}{n-l}$
for some $i \in \curly{2, \ldots, k-1}$
and that all $p_{a_i}$ are odd numbers,
which means they end with a $1$.
In fact,
$p_{a_i}$ for $i \in \curly{2, \ldots, k-1}$
are all the $l$-bit odd numbers except $\rep{1}{l}$.
We will employ the technique of cyclic shifts
again
to span these points efficiently.

Let $\mathcal{T}_1 = \curly{c 1 \rep{1}{n-l}
| c \text{ is a cyclic shift of } 0 \rep{\phi}{l-2}}$.
To see that $\mathcal{T}_1$ spans all the true points
that end with $\rep{1}{n-l}$,
note that the cyclic shifts of $0 \rep{\phi}{l-2}$
span exactly all the $(l-1)$-bit numbers that contain a $0$
and the vectors $c 1$
where $c$ is a cyclic shift of $0 \rep{\phi}{l-2}$
span exactly all the $l$-bit \emph{odd} numbers
that contain a $0$.
Clearly $\size{\mathcal{T}_1} = l-1$.

Similarly we construct $\mathcal{T}_0$ of size $l-1$
that spans all the true points
that end with $\rep{0}{n-l}$.

Putting the partial spanning sets together,
we get the size of a spanning set of $f_l^n$:

\begin{align*}
\size{\mathcal{T}}
&= \size{\mathcal{T}_{\mathit{out}}}
+ \size{\mathcal{T}_0} + \size{\mathcal{T}_1} \\
&= (n-l) + (l-1) + (l-1) \\
&= n + l - 2
\end{align*}
\end{proof}

Having shown a spanning set of $f_l^n$ of size $n+l-2$,
we conclude that $dnf(f_l^n) \leq n+l-2$.

\begin{lemma}
$dnf(f_l^n) \geq n+l-2$
\end{lemma}

\begin{proof}
We will show that $f_l^n$ can not be spanned
using fewer than $n+l-2$ ternary vectors
by showing an orthogonal set of $f_l^n$ of size $n+l-2$.
By \autoref{theorem:orthodnf},
this proves that all the spanning sets of $f_l^n$
have the size at least $n-l-2$.

The orthogonal set $V$ consists of 3 components:
\begin{itemize}
\item
$V_{out} = \curly{\rep{0}{l} s
| s \text{ is a cyclic shift of } 1 \rep{0}{n-l-1}}$
\item
$V_0 = \curly{c 0 \rep{0}{n-l}
| c \text{ is a cyclic shift of } 1 \rep{0}{l-2}}$
\item
$V_1 = \curly{c 1 \rep{1}{n-l}
| c \text{ is a cyclic shift of } 0 \rep{1}{l-2}}$
\end{itemize}

To see that the sets $V_{out}$, $V_0$ and $V_1$
are pairwise disjoint,
consider any $v_{out} \in V_{out}$,
$v_0 \in V_0$ and $v_1 \in V_1$.
The vector $v_1$ differs from both $v_{out}$ and $v_0$
in the $l$-th position.
The vector $v_0$ differs from $v_{out}$
in the position $i \in \curly{1, \ldots, l-1}$
such that $\bit{v_0}{i} = 1$.

Since the sets $V_{out}$, $V_0$ and $V_1$
are pairwise disjoint,
their union $V$
has the size
$\size{V_{out}} + \size{V_0} + \size{V_1}
= (n-l) + (l-1) + (l-1) = n+l-2$.

To see that $V$ is orthogonal with respect to $f^n_l$,
we need to show that any pair of different vectors in $V$
cannot be spanned by a single ternary vector $T$.
Let $x,y \in V$ and $x \neq y$.
Let $T$ span both $x$ and $y$.
We shall consider 6 possible combinations one by one:
\begin{itemize}
\item $x,y \in V_{out}$:
$T$ spans the false point $\rep{0}{n}$.
\item $x,y \in V_0$:
$T$ spans the false point $\rep{0}{n}$.
\item $x,y \in V_1$:
$T$ spans the false point $\rep{1}{n}$.
\item $x \in V_{out}, y \in V_0$:
$T$ spans the false point $\rep{0}{n}$.
\item $x \in V_{out}, y \in V_1$:
$T$ spans the false point $\rep{0}{l} \rep{1}{n-l}$.
\item $x \in V_0, y \in V_1$:
$T$ spans the false point
$\bits{x}{1}{l} \bits{y}{l+1}{n}
= \bits{x}{1}{l-1} 0 \rep{1}{n-l}$.
To see that it is a false point,
recall that
all the true points that end with $\rep{1}{n-l}$
have an \emph{odd} prefix of length $l$.
\end{itemize}

Thus we have found an orthogonal set $V$ of $f_l^n$
of size $n+l-2$.
We conclude that $dnf(f_l^n) \geq n+l-2$.
\end{proof}

\subsection{Approximation ratio on hard functions}

In the previous section,
we have shown that $dnf(f_l^n) = n+l-2$.
We can use this information to prove
that the approximation ratio
of the interval decomposition algorithm is close to $2k$
for large $k$.

The approximation ratio
of the interval decomposition algorithm
on the function $f_l^n$,
denoted $\approxid{f_l^n}$,
can be computed like this:
$$
\approxid{f_l^n}
= \frac{id(f_l^n)}{\mathit{dnf}(f_l^n)}
= \frac{2^l(n-l)}{n+l-2}
$$

Let $\mathit{HARD}(l) = \curly{f_l^n | n \geq l + 2}$
be the set of all \quot{hard} functions constructed using
\quot{position} prefixes of length $l$.
Note that all of these functions
are $(2^{l-1}+1)$-interval,
which means
$\mathit{HARD}(l) \subseteq \intervalfns{2^{l-1}+1}$.

First see that for a fixed $l$ and large $n$,
the approximation ratio converges to $2^l$:
\begin{align*}
\approxid{HARD(l)}
&= \sup_{f \in HARD(l)}{\frac{id(f)}{dnf(f)}} \\
&= \sup_{n \geq l+2}{\frac{id(f_l^n)}{dnf(f_l^n)}} \\
&= \sup_{n \geq l+2}{\frac{2^l(n-l)}{n+l-2}} \\
%&= \lim_{n \rightarrow \infty}{\approxid{f_l^n}} \\
%&= \lim_{n \rightarrow \infty}{\frac{2^l(n-l)}{n+l-2}} \\
%&= \lim_{n \rightarrow \infty}{\frac{2^l n}{n}} \\
&= 2^l
\end{align*}

To see that for any $l \geq 1$
the number $2^l$ really is the supremum of the given sequence,
note that $\frac{n-l}{n+l-2}
= 1 - \frac{2l-2}{n+l-2} \leq 1$
for all $n \geq l+2$
and that
$\lim_{n \rightarrow \infty}{\frac{2^l(n-l)}{n+l-2}}
= \lim_{n \rightarrow \infty}{\frac{2^l n}{n}}
= 2^l$.

Since $2^l$ is the supremum of the approximation ratio
for large $n$,
for any $l \geq 1$ and a number $a < 2^l$,
we can find $n$ such that
%$approx(l,n) \geq a$
$id(f_l^n) \geq a \cdot \mathit{dnf}(f_l^n)$,
which corresponds to finding an instance
on which the interval decomposition algorithm performs
at least $a$ times worse than the optimum.

\begin{example}
\label{example:3inthard}
For example,
let's try to find a $3$-interval function $f$
that can be spanned using
as few as
$\mathit{dnf}(f)$ ternary vectors
while the interval decomposition algorithm uses
strictly more than $3 \cdot \mathit{dnf}(f)$ vectors
to span $f$.

We will find a combination of $l$ and $n$
such that $f_l^n$ is a $3$-interval function
and
$id(f_l^n) > 3 \cdot \mathit{dnf}(f_l^n)$.

Recall that $k = 2^{l-1}+1$,
so we need to use $l = 2$
\todomaybe{Use the inverse mapping ($k \rightarrow l$).}
in order for $f_l^n$ to be $3$-interval.

Now let's choose the parameter $a$.
It needs to satisfy the inequalities $a > 3$
and $a < 4 = 2^l$.
\todomaybe{Why?}
Let's take for example $a = 3.5 = \frac{7}{2}$.

We need to find $n$ such that:
\begin{align*}
id(f_l^n) &= 2^l(n-l) \\
&= 2^2(n-2) \\
&= 4 (n-2) \\
&= 4n - 8 \\
&\geq \frac{7}{2} n \\
&= \frac{7}{2} (n+2-2) \\
&= a (n+l-2) \\
&= a \cdot \mathit{dnf}(f_l^n)
\end{align*}

Any $n \geq 16$ satisfies the inequality:
\begin{align*}
4n - 8 &\geq \frac{7}{2} n \\
8n - 16 &\geq 7n \\
n &\geq 16
\end{align*}

We conclude, for example for $n = 16$:
\begin{align*}
id(f_2^{16})
&= 2^2 (16 - 2) \\
&= 56 \\
&> 48 \\
&= 3 \cdot (16 - 2 + 2) \\
&= 3 \cdot \mathit{dnf}(f_2^{16})
\end{align*}

which means that the interval decomposition algorithm
uses strictly more
than $3$-times as many ternary vectors to span
the $3$-interval function
$f_2^{16}$ as the optimum.

Note that this example namely shows
that the interval decomposition algorithm
is not $k$-approximative in general,
since it is not $3$-approximative
on the $3$-interval function $f_2^{16}$.
\end{example}

\subsection{Approximation ratio lower bound on $k$-interval functions}

In \cref{example:3inthard},
we have shown a $k$-interval function
on which the interval decomposition algorithm performs
strictly more than $k$ times worse than optimum.
More specifically,
the algorithm produces a spanning set
of a $(k=3)$-interval function
that is at least
$\frac{7}{2}
%= \frac{7}{2} \frac{3}{3}
= \frac{7}{6} 3
= \frac{7}{6} k$
times as large as optimum.
On $3$ intervals,
we could get this error ratio arbitrarily close
to $\frac{4}{3} k$
by choosing a sufficiently large $n$.
We will show that if we allow using more intervals
(that is larger $k$),
we can get the error ratio arbitrarily close to $2k$.

For every $k$ such that
there is an $l \geq 1$ such that $k = 2^{l-1} + 1$,
we know that the respective $l$
is equal to $\log_2{(k-1)} + 1$.
Since $\approxid{\mathit{HARD}(l)} = 2^l$ for all $l$,
$\approxidintk \geq 2^{\log_2{(k-1)} + 1}
= 2(k-1)$
for all such $k$.
It is easy to see that $2(k-1)$ converges to $2k$
for large $k$.

In other words,
for any $b < 2$
we can find a $k$-interval function
on which the interval decomposition algorithm
performs at least $bk$ times worse than the optimum.

For demonstration,
\autoref{tab:hardsmalll} shows the limits
of the approximation ratio on $f_l^n$
for some small values of $l$.

\begin{table}[h]
\centering
\begin{tabular}{l|lllll}
$l$
& $k$ % 2^{l-1}+1
& $id(f_l^n)$ % 2^l(n-l)
& $dnf(f_l^n)$ % n+l-2
& $\approxid{\mathit{HARD}(l)}$ % 2^l
& $\frac{\approxid{\mathit{HARD}(l)}}{k}$
% \frac{2^l}{2^{l-1}+1}
\\
\hline
$1$ & $2$ & $2n-4$ & $n-1$ & $2$ & $1$ \\
$2$ & $3$ & $4n-8$ & $n$ & $4$ & $\frac{4}{3}$ \\
$3$ & $5$ & $8n-24$ & $n+1$ & $8$ & $\frac{8}{5}$ \\
$4$ & $9$ & $16n-64$ & $n+2$ & $16$ & $\frac{16}{9}$
\end{tabular}
\caption{Limits of the approximation ratio
on $f_l^n$
for some small $l$}
\label{tab:hardsmalll}
\end{table}

\section{Conclusion}

We have shown an approximation algorithm for the problem of minimization of $k$-interval Boolean functions.
We continued to analyse its approximation ratio.
An upper bound $2k$ on the approximation ratio
directly follows from the analysis of the suffix-prefix decomposition algorithm presented in \autoref{chap:2kapprox}.
A lower bound $2^l = 2(k-1)$
for $k = 2^{l-1}+1$ for every $l \geq 1$
follows from the analysis of the algorithm's performance
on a special class of \quot{hard} functions.
